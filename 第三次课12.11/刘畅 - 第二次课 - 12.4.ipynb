{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二次课\n",
    "1.前30分钟，检测大家的python水平（最好控制在30分钟左右）。\n",
    "\n",
    "2.后30分钟，讲jieba/HanLP/nltk三个分词工具。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测验&作业"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测验：https://www.runoob.com/quiz/python-quiz.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 12186]\n"
     ]
    }
   ],
   "source": [
    "# 数据类型\n",
    "# 题目：生成一个5位数，要求：一、求它是几位数，二、逆序打印出各位数字。\n",
    "import random\n",
    "\n",
    "a = random.randrange(10000, 99999) #生成随机数\n",
    "\n",
    "length = len(str(a)) #获得位数\n",
    "\n",
    "reverse = str(a)[::1] #作为字符串倒置五位数\n",
    "\n",
    "li =[length, int(reverse)]\n",
    "print(li)\n",
    "\n",
    "# 最后输出要求：[5,25341]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "olleh\n",
      "olleh\n",
      "olleh\n"
     ]
    }
   ],
   "source": [
    "# 字符串\n",
    "# 题目：反转字符串，输入\"hello\"，输出\"olleh\"\n",
    "string = \"hello\"\n",
    "\n",
    "print(string[::-1]) #第一种\n",
    "\n",
    "l = len(string)  #第二种\n",
    "reverse = ''\n",
    "for i in range(l-1, -1, -1):\n",
    "    reverse = reverse+string[i]\n",
    "print(reverse)\n",
    "\n",
    "l = len(string)  #第三种\n",
    "r = ''\n",
    "i = 0\n",
    "while i < l:\n",
    "    r = r + string[l-1-i]\n",
    "    i += 1\n",
    "print(r)\n",
    "\n",
    "# 最后要求输出：\"olleh\"，使用三种方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[123, 124, 132, 134, 142, 143, 213, 214, 231, 234, 241, 243, 312, 314, 321, 324, 341, 342, 412, 413, 421, 423, 431, 432]\n"
     ]
    }
   ],
   "source": [
    "# 循环\n",
    "# 题目：有四个数字：1、2、3、4，能组成多少个互不相同且无重复数字的三位数？各是多少？\n",
    "i,j,k,l = 1,2,3,4\n",
    "li = [i, j, k, l]\n",
    "result = []\n",
    "for a in li:\n",
    "    for b in li:\n",
    "        for c in li:\n",
    "            if a != b:\n",
    "                if b != c:\n",
    "                    if a != c:\n",
    "                        num = 100*a+10*b+c\n",
    "                        result.append(num)\n",
    "print(result)\n",
    "# 最后要求输出：[123,124,234,134,......]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 7, 2, 6, 1, 4]\n"
     ]
    }
   ],
   "source": [
    "# 列表\n",
    "# 题目：给定按相反的顺序输出列表的值，并且去重。\n",
    "li = [4, 3, 2, 1, 1, 2, 3, 6, 2, 2, 3, 6, 2, 3, 7, 3, 3]\n",
    "l = len(li)\n",
    "li = li[::-1]\n",
    "print(sorted(set(li), key = li.index))\n",
    "\n",
    "\n",
    "# 最后要求输出：相反的list,且不能有重复。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adam', 'Lisa', 'Bart']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 函数\n",
    "# 给定一个name_list = ['adam', 'LISA', 'barT'],输出首字母大写，后续字母小写的list\n",
    "def normalize(name):\n",
    "    for i in range(len(name)):\n",
    "        name[i] = name[i].capitalize()\n",
    "    return name\n",
    "name_list = ['adam', 'LISA', 'barT']\n",
    "normalize(name_list)\n",
    "\n",
    "# 最后要求输出name_list = ['Adam', 'List', 'Bart']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 25]\n"
     ]
    }
   ],
   "source": [
    "# lambda函数\n",
    "# 题目：请将列表[1,2,3,4,5]使用python方法转变成[1,4,9,16,25]。然后提取大于10的数，最终输出[16,25]\n",
    "l = [1,2,3,4,5]\n",
    "\n",
    "p = lambda a: a*a\n",
    "\n",
    "def power(li):\n",
    "    for i in range(len(li)):\n",
    "        li[i] = p(li[i])\n",
    "    return li\n",
    "\n",
    "l = power(l)\n",
    "\n",
    "new = []\n",
    "\n",
    "for i in range(len(l)):\n",
    "    if l[i] > 10:\n",
    "        new.append(l[i])\n",
    "        \n",
    "print(new)\n",
    "\n",
    "# 最后要求输出:[16,25]，必须使用lambda方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 算法使用部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import jieba\n",
    "from pyhanlp import *\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.add_word('贾宝玉')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打开停用词词表\n",
    "stopwords = []\n",
    "with open(\"stopwords.txt\",\"r\",encoding = \"utf-8\") as f:\n",
    "    for line in f.readlines():\n",
    "        stopwords.append(line.strip(\"\\n\"))\n",
    "        \n",
    "# 载入红楼梦全本，或上面方法打开\n",
    "red_chamber_table = pd.read_table(\"红楼梦.txt\",sep='\\t',header=None)\n",
    "corpus = \"\".join(red_chamber_table[0])\n",
    "\n",
    "# 精准模式切分\n",
    "word_list = jieba.lcut(corpus)\n",
    "\n",
    "# 清洗\n",
    "word_list_clean = []\n",
    "for word in word_list:\n",
    "    if word not in stopwords:\n",
    "        word_list_clean.append(word)\n",
    "    \n",
    "# 统计词频\n",
    "freq_table = pd.DataFrame([dict(Counter(word_list_clean))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_table = freq_table.T\n",
    "freq_table.columns = [\"freq\"]\n",
    "freq_table.sort_values(\"freq\",ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jieba除了精准模式（即默认），还有全切分模式和搜索切分模式\n",
    "# 全切分：速度非常快，但不能解决歧义。\n",
    "segs_all = jieba.cut(corpus, cut_all=True)\n",
    "result = \" \".join(segs_all)\n",
    "\n",
    "# 可以写成lcut\n",
    "# 搜索引擎模式：在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词\n",
    "segs_4 = jieba.cut_for_search(corpus)\n",
    "result = \" \".join(segs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取词性\n",
    "import jieba.posseg as psg\n",
    "segs_5 = [(x.word,x.flag) for x in psg.lcut(corpus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 思考问题：\n",
    "\"\"\"\n",
    "# 我们能不能按照章回，将所有文字切分成一个表格？\n",
    "# 然后来分析每一回的用词，词频？\n",
    "# 使用的最多的动词？使用的最多的名词？使用的最多的形容词？\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 下节课：正则表达式讲解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 算法原理部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# 以词典的为基础的算法，脱不开全切分、正向匹配/反向匹配/双向匹配四种。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['商', '商品', '品', '和', '和服', '服', '服务', '务']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 全切分算法\n",
    "from pyhanlp import *\n",
    "\n",
    "def load_dictionary():\n",
    "    IOUtil = JClass(\"com.hankcs.hanlp.corpus.io.IOUtil\")\n",
    "    path = HanLP.Config.CoreDictionaryPath.replace(\".txt\",\".mini.txt\")\n",
    "    dic = IOUtil.loadDictionary([path])\n",
    "    return set(dic.keySet())\n",
    "\n",
    "def fully_segment(text,dic):\n",
    "    word_list = []\n",
    "    for i in range(len(text)):\n",
    "        for j in range(i + 1,len(text) + 1):\n",
    "            word = text[i:j]\n",
    "            if word in dic:\n",
    "                word_list.append(word)\n",
    "    return word_list\n",
    "\n",
    "# 执行\n",
    "dic = load_dictionary()\n",
    "fully_segment(\"商品和服务\",dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['研究生', '命', '起源']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正向最长匹配\n",
    "def forward_segment(text,dic):\n",
    "    word_list = []\n",
    "    i = 0 \n",
    "    while i < len(text):\n",
    "        longest_word = text[i]\n",
    "        for j in range(i+1,len(text) + 1):\n",
    "            word = text[i:j]\n",
    "            if word in dic:\n",
    "                if len(word) > len(longest_word):\n",
    "                    longest_word = word\n",
    "        word_list.append(longest_word)\n",
    "        i += len(longest_word)\n",
    "    return word_list\n",
    "\n",
    "string = \"研究生命起源\"\n",
    "forward_segment(string,dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['起源']\n",
      "['生命', '起源']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['研究', '生命', '起源']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 反向最长匹配\n",
    "def backward_segment(text,dic):\n",
    "    word_list = []\n",
    "    i = len(text) - 1\n",
    "    while i >= 0:\n",
    "        longest_word = text[i]\n",
    "        for j in range(0,i):\n",
    "            word = text[j:i + 1]\n",
    "            if word in dic:\n",
    "                if len(word) > len(longest_word):\n",
    "                    longest_word = word\n",
    "        print(word_list)\n",
    "        word_list.insert(0,longest_word)\n",
    "        i -= len(longest_word)\n",
    "    return word_list\n",
    "\n",
    "backward_segment(string,dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['起源']\n",
      "['生命', '起源']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['研究', '生命', '起源']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 双向最长匹配\n",
    "def count_single_char(word_list:list):\n",
    "    return sum(1 for word in word_list if len(word) == 1)\n",
    "\n",
    "def bidirectional_segment(text,dic):\n",
    "    f = forward_segment(text,dic)\n",
    "    b = backward_segment(text,dic)\n",
    "    if len(f) < len(b):\n",
    "        return f\n",
    "    elif len(f) > len(b):\n",
    "        return b\n",
    "    else:\n",
    "        if count_single_char(f) < count_single_char(b):\n",
    "            return f\n",
    "        else:\n",
    "            return b\n",
    "        \n",
    "bidirectional_segment(string,dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_speed(segment,text,dic):\n",
    "    start_time = time.time()\n",
    "    for i in range(pressure):\n",
    "        segment(text,dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 想要加速这个词典模型？散列表太慢了，必须用自己构造的字典树。\n",
    "# 构建一颗字典树：\n",
    "class Node(object):\n",
    "    def __init__(self,value) -> None:\n",
    "        # 二叉树的节点\n",
    "        self.children = {}\n",
    "        self._value = value\n",
    "        \n",
    "    def _add_child(self,char,value,overwrite = False):\n",
    "        # 添加节点\n",
    "        child = self._children.get(char)\n",
    "        if child is None:\n",
    "            child = Node(value)\n",
    "            self._children[char] = child\n",
    "        elif overwrite:\n",
    "            child._value = value\n",
    "        return child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trie(Node):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(None)\n",
    "        \n",
    "    def __contains__(self,key):\n",
    "        return self[key] is not None\n",
    "    \n",
    "    def __getitem__(self,key):\n",
    "        state = self"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
