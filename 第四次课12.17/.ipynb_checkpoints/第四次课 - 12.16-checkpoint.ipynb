{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第四次课&第五次课\n",
    "\n",
    "* 前20分钟左右：github与git命令讲解。\n",
    "* 后40分钟左右：讲解作业。\n",
    "\n",
    "\n",
    "\n",
    "### *本周没有作业！*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#git与github\n",
    "\n",
    "# 常用命令\n",
    "# git init\n",
    "# git add [file][.]\n",
    "# git commit -m [status]\n",
    "# git remote add origin [address]\n",
    "# git push -u origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用pandas的简便情况\n",
    "table = pd.read_csv(\"红楼梦.txt\",encoding = \"utf-8\")\n",
    "table.columns = [\"text\"]\n",
    "corpus = \"\".join(table[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 当然这一步也可以不用pandas \n",
    "corpus_list = []\n",
    "with open(\"红楼梦.txt\") as f:\n",
    "    for line in f.readlines():\n",
    "        corpus_list.append(line.strip(\"\\n\"))\n",
    "corpus = \"\".join(corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切分章节\n",
    "# 这个正则怎么写的？\n",
    "pattern = re.compile(\"第[\\u4e00-\\u9fa5]{1,5}回\\\\u3000[\\u4e00-\\u9fa5]{1,10}\\\\u3000[\\u4e00-\\u9fa5]{1,10}\")\n",
    "length = len(list(re.findall(pattern,corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切分：第一种方法:\n",
    "every_chapter = re.split(pattern,corpus)[1:]\n",
    "\n",
    "# 切分：第二种方法：\n",
    "pattern_sub = re.compile(\"(第[\\u4e00-\\u9fa5]{1,5}回\\\\u3000[\\u4e00-\\u9fa5]{1,10}\\\\u3000[\\u4e00-\\u9fa5]{1,10})(\\s{4})\")\n",
    "corpus_anchors = re.sub('(\\s)(第[\\u4e00-\\u9fa5]{1,5}回\\\\u3000[\\u4e00-\\u9fa5]{1,10}\\\\u3000[\\u4e00-\\u9fa5]{1,10})', \n",
    "                        r\"\\1我这里要替换!!!\\2\", corpus)\n",
    "every_chapter = corpus_anchors.split(\"我这里要替换!!!\")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找出每回最多的名字\n",
    "# 在不用pandas的情况下，应该怎么做？\n",
    "import jieba\n",
    "import jieba.posseg\n",
    "from collections import Counter\n",
    "\n",
    "# 过滤词\n",
    "list_stopwords = []\n",
    "with open(\"stopwords.txt\",\"r\",encoding = \"utf-8\") as f:\n",
    "    for word in f.readlines():\n",
    "        list_stopwords.append(word.strip(\"\\n\"))\n",
    "        \n",
    "list_corpus = []\n",
    "\n",
    "def find_freqs(index):\n",
    "    list_every_chapter = []\n",
    "    # 使用jieba工具切分\n",
    "    for item in jieba.lcut(every_chapter[index]):\n",
    "        if item not in list_stopwords:\n",
    "            # 把每一回的分词压入list中\n",
    "            list_every_chapter.append(item)\n",
    "    freq_dicts = dict(Counter(list_every_chapter))\n",
    "    \n",
    "    # 给词典排序\n",
    "    # 注意：这一步用yield也可以，将这个函数变成一个generator，后方循环可以用next()语法，\n",
    "    return sorted(freq_dicts.items(), key=lambda d:d[1], reverse = True)\n",
    "\n",
    "for i in range(0,len(every_chapter)): \n",
    "    list_corpus.append(find_freqs(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('道', 65),\n",
       " ('宝玉', 49),\n",
       " ('说', 30),\n",
       " ('贾琏', 29),\n",
       " ('平儿', 27),\n",
       " ('笑', 27),\n",
       " ('凤姐', 21),\n",
       " ('听', 15),\n",
       " ('湘云', 12),\n",
       " ('劝', 11)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_corpus[0][0:10] # 第一回\n",
    "list_corpus[20][0:10] # 第十一回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [09:18<00:00,  4.82s/it]\n"
     ]
    }
   ],
   "source": [
    "# 找出每回最多的名字\n",
    "# 在不用pandas的情况下，应该怎么做？\n",
    "import jieba\n",
    "import jieba.posseg\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 过滤词\n",
    "list_stopwords = []\n",
    "with open(\"stopwords.txt\",\"r\",encoding = \"utf-8\") as f:\n",
    "    for word in f.readlines():\n",
    "        list_stopwords.append(word.strip(\"\\n\"))\n",
    "        \n",
    "list_corpus = []\n",
    "\n",
    "def find_freqs(index):\n",
    "    list_every_chapter = []\n",
    "    # 使用jieba工具切分\n",
    "    for item in jieba.posseg.lcut(every_chapter[index]):\n",
    "        if item not in list_stopwords:\n",
    "            # 把每一回的分词压入list中\n",
    "            list_every_chapter.append(item)\n",
    "    freq_dicts = dict(Counter(list_every_chapter))\n",
    "    \n",
    "    # 给词典排序\n",
    "    # 注意：这一步用yield也可以，将这个函数变成一个generator，后方循环可以用next()语法，\n",
    "    return sorted(freq_dicts.items(), key=lambda d:d[1], reverse = True)\n",
    "\n",
    "for i in tqdm(range(0,len(every_chapter))): \n",
    "    list_corpus.append(find_freqs(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pickle\\n\\nwith open(\"带词性的词频表.pickle\",\"wb\") as f:\\n    pickle.dump(list_corpus,f)\\n'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 存成pickle文件\n",
    "\"\"\"\n",
    "import pickle\n",
    "\n",
    "with open(\"带词性的词频表.pickle\",\"wb\") as f:\n",
    "    pickle.dump(list_corpus,f)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 过滤只有nr标签的名字\n",
    "list_every_chapter_2,list_corpus_2 = [],[]\n",
    "for i in range(0,len((list_corpus))):\n",
    "    for j in range(0,200):\n",
    "        if tuple(list_corpus[i][j][0])[1] == \"nr\":\n",
    "            list_every_chapter_2.append(list_corpus[i][j])\n",
    "    list_corpus_2.append(list_every_chapter_2)\n",
    "    list_every_chapter_2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存并写入文件\n",
    "import re\n",
    "\n",
    "list_every_chapter_3 = []\n",
    "list_every_chapter_3 = list(map(lambda x:x[0],list_corpus_2))\n",
    "name_freqs_str = list(map(lambda x:str(x),list_every_chapter_3))\n",
    "\n",
    "# 最频繁名字\n",
    "names = list(map(lambda x:re.search(\"[\\u4e00-\\u9fa5]+\",x).group(),name_freqs_str))\n",
    "freqs = list(map(lambda x:re.search(\"\\d+\",x).group(),name_freqs_str))\n",
    "\n",
    "# 写入文件\n",
    "with open(\"频次表.txt\",\"w\",encoding = \"utf-8\") as f:\n",
    "    chapter_index = 1\n",
    "    for name,freq in zip(names,freqs):\n",
    "        line = \"第{}回最多人名:\".format(str(chapter_index)) + str(name) + \",出现频率:\" + str(freq) + \"\\n\"\n",
    "        chapter_index += 1\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pandas的初步学习&学习方法\n",
    "\n",
    "# 最基本方法\n",
    "# pd.Series\n",
    "# pd.DataFrame()\n",
    "\n",
    "# 选取行、列\n",
    "# df[\"column\"]\n",
    "# df.loc[\"columns\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 如果用pandas的情况下\n",
    "DataFrame_list = []\n",
    "for i in range(len(list_corpus)):\n",
    "    table_every_chapter = pd.DataFrame(list_corpus[i])\n",
    "    table_every_chapter.columns = [\"word\",\"freq\"]\n",
    "    table_every_chapter = table_every_chapter[0:100]\n",
    "    DataFrame_list.append(table_every_chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_combined = pd.concat(DataFrame_list,axis = 1)[\"word\"]\n",
    "table_combined.columns = [\"word_\" + str(i) for i in range(1,121)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_combined = table_combined.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取所有的词性，并且筛去其他词性的词\n",
    "table_combined = table_combined.applymap(lambda x:jieba.posseg.lcut(x)[0])\n",
    "table_combined2 = table_combined[table_combined.applymap(lambda x:\"nr\" in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将nan全部替换成0，便于下部操作\n",
    "table_combined2.fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 表格过滤\n",
    "list_top_names = []\n",
    "for i in range(1,121):\n",
    "    index = \"word_\" + str(i)\n",
    "    top_name_every_chapter = list(filter(lambda x:x != 0,table_combined2.T[index]))\n",
    "    list_top_names.append(top_name_every_chapter[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最终前三个名字\n",
    "table_final = pd.DataFrame(list_top_names).applymap(lambda x:str(x).strip(\"/nr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>士隐</td>\n",
       "      <td>那僧</td>\n",
       "      <td>那僧道</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>子兴道</td>\n",
       "      <td>老爹</td>\n",
       "      <td>小姐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>黛玉</td>\n",
       "      <td>宝玉</td>\n",
       "      <td>王夫人</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>薛蟠</td>\n",
       "      <td>王夫人</td>\n",
       "      <td>薛家</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>宝玉</td>\n",
       "      <td>秦氏</td>\n",
       "      <td>金陵</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0   士隐   那僧  那僧道\n",
       "1  子兴道   老爹   小姐\n",
       "2   黛玉   宝玉  王夫人\n",
       "3   薛蟠  王夫人   薛家\n",
       "4   宝玉   秦氏   金陵"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 答案\n",
    "table_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 另一种方法(写完发现其实是一样的......思路如下)\n",
    "table_combined3 = table_combined2.T\n",
    "\n",
    "# 复制range向量\n",
    "copy_arraies = np.repeat([range(100,0,-1)],100,axis = 0)\n",
    "\n",
    "# 每个词表\n",
    "every_chapter_names = list(map(lambda x:table_combined3[x],table_combined3.columns))\n",
    "\n",
    "# 做出120个表格\n",
    "every_chapter_names_table = list(map(lambda x,y:pd.DataFrame([x,y]),every_chapter_names,copy_arraies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
